{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Phishing_Dataset.csv')\n",
    "\n",
    "def checkSpecial(string): \n",
    "    # Make own character set and pass  \n",
    "    # this as argument in compile method \n",
    "    regex = re.compile('[@_!#$%^&*()<>?|}{~]') \n",
    "    i=0\n",
    "    for char in string:   \n",
    "        if regex.search(char): \n",
    "            i+=1\n",
    "    return i\n",
    "\n",
    "def getNums(str):\n",
    "    i=0\n",
    "    for char in str: \n",
    "        if char.isdigit():\n",
    "            i+=1\n",
    "    return i\n",
    "\n",
    "def entropy(url):\n",
    "        string = url.strip()\n",
    "        prob = [float(string.count(c)) / len(string) for c in dict.fromkeys(list(string))]\n",
    "        entropy = sum([(p * math.log(p) / math.log(2.0)) for p in prob])\n",
    "        return entropy\n",
    "\n",
    "def numSubDomains(url):\n",
    "    subdomains = url.split('http')[-1].split('//')[-1].split('/')\n",
    "    return len(subdomains)-1\n",
    "\n",
    "def feature_transform(df):\n",
    "    df.insert(2,'len_url', [len(url) for url in df['URL']])\n",
    "\n",
    "\n",
    "    df.insert(2,'numerical',[getNums(url) for url in df['URL']])\n",
    "\n",
    "    df.insert(2,'special',[checkSpecial(url) for url in df['URL']])\n",
    "\n",
    "    df.insert(2, 'hasPercent', [('%' in url) for url in df['URL']])\n",
    "\n",
    "    #df.insert(2, 'entropy', [entropy(url) for url in df['URL']])\n",
    "\n",
    "    df.insert(2, 'numSD', [numSubDomains(url) for url in df['URL']])\n",
    "\n",
    "    del df['URL']\n",
    "\n",
    "feature_transform(df)\n",
    "\n",
    "#split into parameters and label for supervised learning\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "data_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.2, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#train model\n",
    "xg_reg = xgb.XGBClassifier(learning_rate=0.2)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 Score on training dataset:\n0.9408450704225352\n"
    }
   ],
   "source": [
    "#predictions /validation \n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "preds = xg_reg.predict(X_test)\n",
    "predictions = [round(value) for value in preds]\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "#score = accuracy_score(y_test,predictions)\n",
    "#print(score)\n",
    "print(\"F1 Score on training dataset:\")\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f1)\n",
    "\n",
    "# testing \n",
    "# test_data = pd.read_csv('./Phishing_Test.csv')\n",
    "# ids = test_data['Unnamed: 0']\n",
    "# urls = test_data['URL']\n",
    "# del test_data['Unnamed: 0']\n",
    "# del test_data['Label']\n",
    "\n",
    "# feature_transform(test_data)\n",
    "# labels = xg_reg.predict(test_data)\n",
    "\n",
    "# def unfeaturize(data):\n",
    "#     del data['numSD']\n",
    "#     del data['hasPercent']\n",
    "#     del data['special']\n",
    "#     del data['numerical']\n",
    "#     del data['len_url']\n",
    "\n",
    "# unfeaturize(test_data)\n",
    "# test_data.insert(0, '',ids )\n",
    "# test_data.insert(4, 'URL', urls)\n",
    "# test_data.insert(5, 'Label', labels)\n",
    "\n",
    "# test_data.to_csv(r'./Phishing_Labels.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597542867086",
   "display_name": "Python 3.7.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}