{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597615650631",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSpecial(url):\n",
    "    \"\"\"Returns number of special characters in string\"\"\"\n",
    "    regex = re.compile('[@_!#$%^&*()<>?|}{~]')\n",
    "    return len([c for c in url if regex.search(c)])\n",
    "\n",
    "def getNums(url):\n",
    "    \"\"\"Returns number of digits in string\"\"\"\n",
    "    return len([c for c in url if c.isdigit()])\n",
    "\n",
    "def entropy(url):\n",
    "    \"\"\"Returns entropy of string\"\"\"\n",
    "    s = url.strip()\n",
    "    prob = [float(s.count(c)) / len(s) for c in dict.fromkeys(list(s))]\n",
    "    ent = sum([(p * math.log(p) / math.log(2.0)) for p in prob])\n",
    "    return ent\n",
    "\n",
    "def numSubDomains(url):\n",
    "    \"\"\"Returns number of subdomains in the given URL\"\"\"\n",
    "    subdomains = url.split('http')[-1].split('//')[-1].split('/')\n",
    "    return len(subdomains)-1\n",
    "\n",
    "def feature_transform(df):\n",
    "    \"\"\"Featurizes the URL string into the data frame\"\"\"\n",
    "    df.insert(2, 'len_url', [len(url) for url in df['URL']])\n",
    "    df.insert(2, 'numerical', [getNums(url) for url in df['URL']])\n",
    "    df.insert(2, 'special', [checkSpecial(url) for url in df['URL']])\n",
    "    df.insert(2, 'hasPercent', [1 if ('%' in url) else 0 for url in df['URL']])\n",
    "    df.insert(2, 'entropy', [entropy(url) for url in df['URL']])\n",
    "    df.insert(2, 'numSD', [numSubDomains(url) for url in df['URL']])\n",
    "    del df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Phishing_Dataset.csv')\n",
    "feature_transform(df)\n",
    "\n",
    "y = df.pop('Label')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def norm(x):\n",
    "  return (x - x.mean())/x.std()\n",
    "\n",
    "normed_train = norm(x_train)\n",
    "normed_test = norm(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=[len(x_train.columns)]),\n",
    "     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(25, activation='relu', kernel_initializer='he_normal'),\n",
    "     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_28\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_94 (Dense)             (None, 100)               1000      \n_________________________________________________________________\ndropout_23 (Dropout)         (None, 100)               0         \n_________________________________________________________________\ndense_95 (Dense)             (None, 50)                5050      \n_________________________________________________________________\ndense_96 (Dense)             (None, 25)                1275      \n_________________________________________________________________\ndropout_24 (Dropout)         (None, 25)                0         \n_________________________________________________________________\ndense_97 (Dense)             (None, 1)                 26        \n=================================================================\nTotal params: 7,351\nTrainable params: 7,351\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/150\n96/96 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8147 - val_loss: 0.2749 - val_accuracy: 0.8958\nEpoch 2/150\n96/96 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8824 - val_loss: 0.2604 - val_accuracy: 0.8971\nEpoch 3/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8854 - val_loss: 0.2517 - val_accuracy: 0.9010\nEpoch 4/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8951 - val_loss: 0.2437 - val_accuracy: 0.9049\nEpoch 5/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8922 - val_loss: 0.2437 - val_accuracy: 0.9036\nEpoch 6/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8942 - val_loss: 0.2415 - val_accuracy: 0.9115\nEpoch 7/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8981 - val_loss: 0.2308 - val_accuracy: 0.9102\nEpoch 8/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.9020 - val_loss: 0.2221 - val_accuracy: 0.9128\nEpoch 9/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9049 - val_loss: 0.2208 - val_accuracy: 0.9128\nEpoch 10/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9000 - val_loss: 0.2228 - val_accuracy: 0.9089\nEpoch 11/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9072 - val_loss: 0.2233 - val_accuracy: 0.9089\nEpoch 12/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9017 - val_loss: 0.2146 - val_accuracy: 0.9076\nEpoch 13/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9078 - val_loss: 0.2202 - val_accuracy: 0.9167\nEpoch 14/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9062 - val_loss: 0.2128 - val_accuracy: 0.9115\nEpoch 15/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9056 - val_loss: 0.2096 - val_accuracy: 0.9102\nEpoch 16/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9088 - val_loss: 0.2088 - val_accuracy: 0.9128\nEpoch 17/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9140 - val_loss: 0.2097 - val_accuracy: 0.9102\nEpoch 18/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9108 - val_loss: 0.2068 - val_accuracy: 0.9128\nEpoch 19/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9137 - val_loss: 0.2019 - val_accuracy: 0.9141\nEpoch 20/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9186 - val_loss: 0.2059 - val_accuracy: 0.9102\nEpoch 21/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9134 - val_loss: 0.2052 - val_accuracy: 0.9154\nEpoch 22/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9144 - val_loss: 0.2052 - val_accuracy: 0.9180\nEpoch 23/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9205 - val_loss: 0.2143 - val_accuracy: 0.9128\nEpoch 24/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9186 - val_loss: 0.2014 - val_accuracy: 0.9167\nEpoch 25/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9170 - val_loss: 0.2007 - val_accuracy: 0.9115\nEpoch 26/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9163 - val_loss: 0.2009 - val_accuracy: 0.9141\nEpoch 27/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9192 - val_loss: 0.2021 - val_accuracy: 0.9115\nEpoch 28/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9157 - val_loss: 0.2001 - val_accuracy: 0.9193\nEpoch 29/150\n96/96 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9163 - val_loss: 0.2030 - val_accuracy: 0.9167\n"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5)\n",
    "\n",
    "history = model.fit(normed_train, y_train, epochs=150, batch_size=32, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30/30 [==============================] - 0s 846us/step - loss: 0.2109 - accuracy: 0.9135\n"
    }
   ],
   "source": [
    "score = model.evaluate(normed_test, y_test)\n",
    "\n",
    "# test_predictions = model.predict(normed_test).flatten()\n",
    "# predictions = [int(round(value)) for value in test_predictions]\n",
    "# print(predictions)"
   ]
  }
 ]
}